name: uva
dataloader:
  batch_size: 8
  num_workers: 8
  persistent_workers: false
  pin_memory: true
  shuffle: true
val_dataloader:
  batch_size: 32
  num_workers: 8
  persistent_workers: false
  pin_memory: true
  shuffle: false
training:
  checkpoint_every: 10
  debug: false
  device: cuda:0
  gradient_accumulate_every: 1
  lr_scheduler: cosine
  lr_warmup_steps: 1000
  max_train_steps: null
  max_val_steps: null
  num_epochs: 50
  resume: true
  rollout_every: 10
  sample_every: 5
  seed: 42
  tqdm_interval_sec: 1.0
  use_ema: true
  val_every: 1
  mixed_precision: fp16
checkpoint:
  save_last_ckpt: true
  save_last_snapshot: false
  topk:
    monitor_key: test_mean_score
    format_str: epoch={epoch:04d}-test_mean_score={test_mean_score:.3f}.ckpt
    k: 1
    mode: max
ema:
  _target_: unified_video_action.model.autoregressive.ema_model.EMAModel
  inv_gamma: 1.0
  max_value: 0.9999
  min_value: 0.0
  power: 0.75
  update_after_step: 0
logging:
  group: null
  id: null
  mode: offline
  name: train_uva_pusht
  project: unified_video_action
  resume: true
  tags:
  - train_uva_pusht
  - pusht
  - default
multi_run:
  run_dir: data/outputs/train_uva_pusht
  wandb_name_base: train_uva_pusht
task:
  name: pusht
  task_type: single_dataset
  task_modes: []
  shape_meta:
    image_resolution: 96
    action:
      shape:
      - 2
    obs:
      agent_pos:
        shape:
        - 2
        type: low_dim
      image:
        shape:
        - 3
        - 96
        - 96
        type: rgb
  dataset:
    _target_: unified_video_action.dataset.pusht_image_dataset.PushTImageDataset
    language_emb_model: null
    horizon: 32
    pad_after: 7
    pad_before: 1
    seed: 42
    val_ratio: 0.02
    data_aug: true
    normalizer_type: all
    dataset_path: data/pusht/pusht_cchi_v7_replay.zarr
    dataset_type: singletask
  env_runner:
    _target_: unified_video_action.env_runner.pusht_image_runner.PushTImageRunner
    fps: 10
    legacy_test: true
    max_steps: 300
    n_action_steps: 8
    n_envs: null
    n_obs_steps: 16
    n_test: 50
    n_test_vis: 4
    n_train: 6
    n_train_vis: 2
    past_action: false
    test_start_seed: 100000
    train_start_seed: 0
    fix_goal: true
model:
  _target_: unified_video_action.workspace.train_unified_video_action_workspace.TrainUnifiedVideoActionWorkspace
  policy:
    _target_: unified_video_action.policy.unified_video_action_policy.UnifiedVideoActionPolicy
    selected_training_mode: null
    debug: None
    n_action_steps: 8
    use_proprioception: null
    use_history_action: null
    action_mask_ratio: 0.5
    different_history_freq: null
    predict_wrist_img: null
    predict_proprioception: null
    shape_meta: ${task.shape_meta}
    vae_model_params:
      autoencoder_path: pretrained_models/vae/kl16.ckpt
      ddconfig:
        vae_embed_dim: 16
        ch_mult:
        - 1
        - 1
        - 2
        - 2
        - 4
    autoregressive_model_params:
      pretrained_model_path: checkpoints/improved_phase1_local_only.ckpt
      model_size: mar_base
      img_size: 256
      vae_stride: 16
      patch_size: 1
      vae_embed_dim: 16
      mask_ratio_min: 0.7
      label_drop_prob: 0.1
      attn_dropout: 0.1
      proj_dropout: 0.1
      diffloss_d: 6
      diffloss_w: 1024
      diffloss_act_d: 6
      diffloss_act_w: 1024
      num_sampling_steps: '100'
      diffusion_batch_mul: 1
      grad_checkpointing: false
      num_iter: 1
      cfg: 1
      cfg_schedule: linear
      temperature: 0.95
      predict_video: true
      act_diff_training_steps: 1000
      act_diff_testing_steps: '100'
    action_model_params:
      predict_action: true
      act_model_type: conv_fc
    shift_action: true
    optimizer:
      learning_rate: 5.0e-05
      weight_decay: 0.02
      betas:
      - 0.9
      - 0.95
